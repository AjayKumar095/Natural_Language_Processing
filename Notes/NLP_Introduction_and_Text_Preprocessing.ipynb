{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style='color: green;'><center>NLP Introduction and Text Preprocessing</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color: blue;\">1. What is the primary goal of Natural Language Processing (NLP)?</h3>\n",
    "    <p>The primary goal of NLP is to enable machines to understand, interpret, and generate human language in a way that is meaningful and useful. It bridges the gap between human communication and machine understanding.</p>\n",
    "    \n",
    "<h3 style=\"color: blue;\">2. What does \"tokenization\" refer to in text processing?</h3>\n",
    "    <p>Tokenization refers to the process of breaking down text into smaller units, called tokens, which could be words, phrases, or sentences. For example, splitting \"I love NLP\" into [\"I\", \"love\", \"NLP\"].</p>\n",
    "\n",
    "<h3 style=\"color: blue;\">3. What is the difference between lemmatization and stemming?</h3>\n",
    "    <p>Stemming reduces a word to its base or root form by cutting off prefixes or suffixes (e.g., \"running\" to \"run\"). Lemmatization does the same but uses vocabulary and grammar rules to return the word to its dictionary form (e.g., \"better\" to \"good\").</p>\n",
    "\n",
    "<h3 style=\"color: blue;\">4. What is the role of regular expressions (regex) in text processing?</h3>\n",
    "    <p>Regex is used to identify patterns in text, such as finding email addresses, phone numbers, or specific words. It simplifies text cleaning and data extraction tasks.</p>\n",
    "\n",
    "<h3 style=\"color: blue;\">5. What is Word2Vec and how does it represent words in a vector space?</h3>\n",
    "    <p>Word2Vec is a technique for representing words as dense vectors in a high-dimensional space. It captures semantic relationships between words, making similar words have closer vector representations.</p>\n",
    "\n",
    "<h3 style=\"color: blue;\">6. How does frequency distribution help in text analysis?</h3>\n",
    "    <p>Frequency distribution helps identify the most common words or terms in a dataset, providing insights into the content and helping to prioritize key terms in analysis.</p>\n",
    "\n",
    "<h3 style=\"color: blue;\">7. Why is text normalization important in NLP?</h3>\n",
    "    <p>Text normalization ensures consistency by converting text into a standard format. It involves tasks like lowercasing, removing punctuation, and handling misspellings.</p>\n",
    "\n",
    "<h3 style=\"color: blue;\">8. What is the difference between sentence tokenization and word tokenization?</h3>\n",
    "    <p>Sentence tokenization splits text into individual sentences, while word tokenization breaks sentences into words.</p>\n",
    "\n",
    "<h3 style=\"color: blue;\">9. What are co-occurrence vectors in NLP?</h3>\n",
    "    <p>Co-occurrence vectors represent the context of a word by counting how often it appears with other words in a window of text, helping to capture semantic relationships.</p>\n",
    "\n",
    "<h3 style=\"color: blue;\">10. What is the significance of lemmatization in improving NLP tasks?</h3>\n",
    "    <p>Lemmatization reduces words to their root forms, improving the consistency of input text and reducing redundancy for NLP tasks like search engines or sentiment analysis.</p>\n",
    "\n",
    "<h3 style=\"color: blue;\">11. What is the primary use of word embeddings in NLP?</h3>\n",
    "    <p>Word embeddings are used to represent words in a vector space where semantic similarity is preserved, aiding tasks like text classification and machine translation.</p>\n",
    "\n",
    "<h3 style=\"color: blue;\">12. What is an annotator in NLP?</h3>\n",
    "    <p>An annotator is a tool or software used to label data with relevant information, such as tagging parts of speech, named entities, or sentiment in a text.</p>\n",
    "\n",
    "<h3 style=\"color: blue;\">13. What are the key steps in text processing before applying machine learning models?</h3>\n",
    "    <ul>\n",
    "        <li>Text cleaning (removing noise, punctuation, etc.)</li>\n",
    "        <li>Tokenization</li>\n",
    "        <li>Text normalization (lowercasing, stemming/lemmatization)</li>\n",
    "        <li>Vectorization (converting text to numerical format)</li>\n",
    "    </ul>\n",
    "\n",
    "<h3 style=\"color: blue;\">14. What is the history of NLP and how has it evolved?</h3>\n",
    "    <p>NLP has evolved from rule-based systems in the 1950s to statistical models and machine learning in the 1980s, followed by deep learning techniques in the 2010s.</p>\n",
    "\n",
    "<h3 style=\"color: blue;\">15. Why is sentence processing important in NLP?</h3>\n",
    "    <p>Sentence processing helps in tasks like summarization, sentiment analysis, and translation by analyzing the meaning and structure of sentences.</p>\n",
    "\n",
    "<h3 style=\"color: blue;\">16. How do word embeddings improve the understanding of language semantics in NLP?</h3>\n",
    "    <p>Word embeddings encode semantic relationships, making words with similar meanings have closer representations in a vector space, aiding in context-based tasks.</p>\n",
    "\n",
    "<h3 style=\"color: blue;\">17. How does the frequency distribution of words help in text classification?</h3>\n",
    "    <p>Frequency distribution highlights the most relevant terms for classification, helping identify features that distinguish categories.</p>\n",
    "\n",
    "<h3 style=\"color: blue;\">18. What are the advantages of using regex in text cleaning?</h3>\n",
    "    <p>Regex simplifies identifying patterns, cleaning data, and extracting specific information like dates, emails, or URLs.</p>\n",
    "\n",
    "<h3 style=\"color: blue;\">19. What is the difference between Word2Vec and Doc2Vec?</h3>\n",
    "    <p>Word2Vec generates vectors for individual words, while Doc2Vec extends this to create vectors for entire documents or paragraphs, capturing their meaning.</p>\n",
    "\n",
    "<h3 style=\"color: blue;\">20. Why is understanding text normalization important in NLP?</h3>\n",
    "    <p>Text normalization ensures that text is consistent and free of variations, enabling better model performance and comparability.</p>\n",
    "\n",
    "<h3 style=\"color: blue;\">21. How does word count help in text analysis?</h3>\n",
    "    <p>Word count identifies the frequency of terms, providing insights into the main topics and themes in a text corpus.</p>\n",
    "\n",
    "<h3 style=\"color: blue;\">22. How does lemmatization help in NLP tasks like search engines and chatbots?</h3>\n",
    "    <p>Lemmatization reduces word variations, improving search relevance and chatbot understanding by focusing on word meanings.</p>\n",
    "\n",
    "<h3 style=\"color: blue;\">23. What is the purpose of using Doc2Vec in text processing?</h3>\n",
    "    <p>Doc2Vec creates vector representations of documents, enabling tasks like document similarity, clustering, and classification.</p>\n",
    "\n",
    "<h3 style=\"color: blue;\">24. What is the importance of sentence processing in NLP?</h3>\n",
    "    <p>Sentence processing helps understand the structure and meaning of text, which is crucial for translation, summarization, and other tasks.</p>\n",
    "\n",
    "<h3 style=\"color: blue;\">25. What is text normalization, and what are the common techniques used in it?</h3>\n",
    "    <p>Text normalization converts text to a consistent format using techniques like lowercasing, stemming, lemmatization, and removing special characters.</p>\n",
    "\n",
    "<h3 style=\"color: blue;\">26. Why is word tokenization important in NLP?</h3>\n",
    "    <p>Word tokenization breaks text into words, which is a fundamental step for analyzing and processing language.</p>\n",
    "\n",
    "<h3 style=\"color: blue;\">27. How does sentence tokenization differ from word tokenization in NLP?</h3>\n",
    "    <p>Sentence tokenization splits text into sentences, while word tokenization focuses on dividing sentences into individual words.</p>\n",
    "\n",
    "<h3 style=\"color: blue;\">28. What is the primary purpose of text processing in NLP?</h3>\n",
    "    <p>Text processing prepares raw text for analysis by cleaning, normalizing, and transforming it into a usable format for NLP models.</p>\n",
    "\n",
    "<h3 style=\"color: blue;\">29. What are the key challenges in NLP?</h3>\n",
    "    <ul>\n",
    "        <li>Understanding context and ambiguity</li>\n",
    "        <li>Handling idioms and figurative language</li>\n",
    "        <li>Processing different languages and dialects</li>\n",
    "        <li>Scaling to large datasets</li>\n",
    "    </ul>\n",
    "\n",
    "<h3 style=\"color: blue;\">30. How do co-occurrence vectors represent relationships between words?</h3>\n",
    "    <p>Co-occurrence vectors capture relationships by counting how often words appear together in a specific context, helping in semantic analysis.</p>\n",
    "\n",
    "<h3 style=\"color: blue;\">31. What is the role of frequency distribution in text analysis?</h3>\n",
    "    <p>Frequency distribution identifies common terms and patterns in text, aiding in feature selection and thematic analysis.</p>\n",
    "\n",
    "<h3 style=\"color: blue;\">32. What is the impact of word embeddings on NLP tasks?</h3>\n",
    "    <p>Word embeddings improve NLP tasks by encoding semantic and syntactic information, enabling better performance in tasks like translation and sentiment analysis.</p>\n",
    "\n",
    "<h3 style=\"color: blue;\">33. What is the purpose of using lemmatization in text preprocessing?</h3>\n",
    "    <p>Lemmatization reduces words to their root forms, improving consistency and reducing data redundancy, making models more efficient and accurate.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style='color:green;'><center>Practical</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. How can you perform word tokenization using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'primary', 'goal', 'of', 'NLP', 'is', 'to', 'enable', 'machines', 'to', 'understand', ',', 'interpret', ',', 'and', 'generate', 'human', 'language', 'in', 'a', 'way', 'that', 'is', 'meaningful', 'and', 'useful', '.', 'It', 'bridges', 'the', 'gap', 'between', 'human', 'communication', 'and', 'machine', 'understanding', '.']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from nltk.tokenize import  word_tokenize\n",
    "\n",
    "## sample text data \n",
    "corpus = \"\"\"The primary goal of NLP is to enable machines to understand, interpret,\n",
    "            and generate human language in a way that is meaningful and useful.\n",
    "            It bridges the gap between human communication and machine understanding.\"\"\"\n",
    "            \n",
    "word_tokens = word_tokenize(text=corpus, language='english')         \n",
    "print(word_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. How can you perform sentence tokenization using NLTK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The primary goal of NLP is to enable machines to understand, interpret,\\n            and generate human language in a way that is meaningful and useful.', 'It bridges the gap between human communication and machine understanding.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import  sent_tokenize\n",
    "\n",
    "## sample text data \n",
    "corpus = \"\"\"The primary goal of NLP is to enable machines to understand, interpret,\n",
    "            and generate human language in a way that is meaningful and useful.\n",
    "            It bridges the gap between human communication and machine understanding.\"\"\"\n",
    "            \n",
    "sent_tokens = sent_tokenize(text=corpus, language='english')         \n",
    "print(sent_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. How can you remove stopwords from a sentence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['primary', 'goal', 'NLP', 'enable', 'machines', 'understand', ',', 'interpret', ',', 'generate', 'human', 'language', 'way', 'meaningful', 'useful', '.', 'bridges', 'gap', 'human', 'communication', 'machine', 'understanding', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "## sample text data \n",
    "corpus = \"\"\"The primary goal of NLP is to enable machines to understand, interpret,\n",
    "            and generate human language in a way that is meaningful and useful.\n",
    "            It bridges the gap between human communication and machine understanding.\"\"\"\n",
    "            \n",
    "word_tokens = word_tokenize(text=corpus, language='english')\n",
    "\n",
    "## removing stopwords for the above corpus\n",
    "clean_data  = [ word for word in word_tokens if word.lower() not in stopwords.words('english')]\n",
    "print(clean_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. How can you perform stemming on a word?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['primari', 'goal', 'nlp', 'enabl', 'machin', 'understand', ',', 'interpret', ',', 'gener', 'human', 'languag', 'way', 'meaning', 'use', '.', 'bridg', 'gap', 'human', 'commun', 'machin', 'understand', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer ## for stemming\n",
    "\n",
    "## sample text data \n",
    "corpus = \"\"\"The primary goal of NLP is to enable machines to understand, interpret,\n",
    "            and generate human language in a way that is meaningful and useful.\n",
    "            It bridges the gap between human communication and machine understanding.\"\"\"\n",
    "            \n",
    "word_tokens = word_tokenize(text=corpus, language='english')\n",
    "## initializing the stemmer object\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "## removing stopwords and applying stemming for the above corpus\n",
    "clean_data  = [ stemmer.stem(word) for word in word_tokens if word.lower() not in stopwords.words('english')]\n",
    "print(clean_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. How can you perform lemmatization on a word?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['primary', 'goal', 'NLP', 'enable', 'machine', 'understand', ',', 'interpret', ',', 'generate', 'human', 'language', 'way', 'meaningful', 'useful', '.', 'bridge', 'gap', 'human', 'communication', 'machine', 'understanding', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer ## for lemmatization\n",
    "\n",
    "## sample text data \n",
    "corpus = \"\"\"The primary goal of NLP is to enable machines to understand, interpret,\n",
    "            and generate human language in a way that is meaningful and useful.\n",
    "            It bridges the gap between human communication and machine understanding.\"\"\"\n",
    "            \n",
    "word_tokens = word_tokenize(text=corpus, language='english')\n",
    "## initializing the WordNetLemmatizer object\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "## removing stopwords and applying stemming for the above corpus\n",
    "clean_data  = [ lemmatizer.lemmatize(word) for word in word_tokens if word.lower() not in stopwords.words('english')]\n",
    "print(clean_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. How can you normalize a text by converting it to lowercase and removing punctuation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'primary', 'goal', 'of', 'nlp', 'is', 'to', 'enable', 'machines', 'to', 'understand', ' ', 'interpret', ' ', 'and', 'generate', 'human', 'language', 'in', 'a', 'way', 'that', 'is', 'meaningful', 'and', 'useful', ' ', 'it', 'bridges', 'the', 'gap', 'between', 'human', 'communication', 'and', 'machine', 'understanding', ' ']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "## sample text data \n",
    "corpus = \"\"\"The primary goal of NLP is to enable machines to understand, interpret,\n",
    "            and generate human language in a way that is meaningful and useful.\n",
    "            It bridges the gap between human communication and machine understanding.\"\"\"\n",
    "            \n",
    "word_tokens = word_tokenize(text=corpus, language='english')\n",
    "\n",
    "normalized_corpus = [ re.sub('[^a-zA-Z]',' ', word).lower() for word in word_tokens]      \n",
    "print(normalized_corpus)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. How can you create a co-occurrence matrix for words in a corpus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>chased</th>\n",
       "      <th>dog</th>\n",
       "      <th>log</th>\n",
       "      <th>mat</th>\n",
       "      <th>on</th>\n",
       "      <th>sat</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chased</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dog</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mat</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>on</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sat</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        cat  chased  dog  log  mat  on  sat  the\n",
       "cat       2       1    1    0    1   1    1    4\n",
       "chased    1       1    1    0    0   0    0    2\n",
       "dog       1       1    2    1    0   1    1    4\n",
       "log       0       0    1    1    0   1    1    2\n",
       "mat       1       0    0    0    1   1    1    2\n",
       "on        1       0    1    1    1   2    2    4\n",
       "sat       1       0    1    1    1   2    2    4\n",
       "the       4       2    4    2    2   4    4   12"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Sample corpus\n",
    "corpus = [\n",
    "    \"the cat sat on the mat\",\n",
    "    \"the dog sat on the log\",\n",
    "    \"the cat chased the dog\"\n",
    "]\n",
    "\n",
    "# Create a co-occurrence matrix\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Generate Co-occurrence Matrix\n",
    "co_matrix = (X.T * X).toarray()\n",
    "vocab = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Convert to a DataFrame\n",
    "co_matrix_df = pd.DataFrame(co_matrix, index=vocab, columns=vocab)\n",
    "co_matrix_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. How can you apply a regular expression to extract all email addresses from a text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['example@gmail.com', 'test_email@domain.org']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Sample text\n",
    "text = \"\"\"\n",
    "Hello, you can contact me at example@gmail.com or at test_email@domain.org. \n",
    "Feel free to reach out anytime.\n",
    "\"\"\"\n",
    "\n",
    "# Extract email addresses\n",
    "emails = re.findall(r\"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\", text)\n",
    "emails\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.How can you perform word embedding using Word2Vec?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00713902,  0.00124103, -0.00717672, -0.00224462,  0.0037193 ,\n",
       "        0.00583312,  0.00119818,  0.00210273, -0.00411039,  0.00722533,\n",
       "       -0.00630704,  0.00464722, -0.00821997,  0.00203647, -0.00497705,\n",
       "       -0.00424769, -0.00310898,  0.00565521,  0.0057984 , -0.00497465,\n",
       "        0.00077333, -0.00849578,  0.00780981,  0.00925729, -0.00274233,\n",
       "        0.00080022,  0.00074665,  0.00547788, -0.00860608,  0.00058446,\n",
       "        0.00686942,  0.00223159,  0.00112468, -0.00932216,  0.00848237,\n",
       "       -0.00626413, -0.00299237,  0.00349379, -0.00077263,  0.00141129,\n",
       "        0.00178199, -0.0068289 , -0.00972481,  0.00904058,  0.00619805,\n",
       "       -0.00691293,  0.00340348,  0.00020606,  0.00475375, -0.00711994,\n",
       "        0.00402695,  0.00434743,  0.00995737, -0.00447374, -0.00138926,\n",
       "       -0.00731732, -0.00969783, -0.00908026, -0.00102275, -0.00650329,\n",
       "        0.00484973, -0.00616403,  0.00251919,  0.00073944, -0.00339215,\n",
       "       -0.00097922,  0.00997913,  0.00914589, -0.00446183,  0.00908303,\n",
       "       -0.00564176,  0.00593092, -0.00309722,  0.00343175,  0.00301723,\n",
       "        0.00690046, -0.00237388,  0.00877504,  0.00758943, -0.00954765,\n",
       "       -0.00800821, -0.0076379 ,  0.00292326, -0.00279472, -0.00692952,\n",
       "       -0.00812826,  0.00830918,  0.00199049, -0.00932802, -0.00479272,\n",
       "        0.00313674, -0.00471321,  0.00528084, -0.00423344,  0.0026418 ,\n",
       "       -0.00804569,  0.00620989,  0.00481889,  0.00078719,  0.00301345],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Sample text corpus\n",
    "sentences = [\n",
    "    \"the cat sat on the mat\",\n",
    "    \"the dog sat on the log\",\n",
    "    \"the cat chased the dog\"\n",
    "]\n",
    "\n",
    "# Tokenize sentences\n",
    "tokenized_sentences = [word_tokenize(sentence) for sentence in sentences]\n",
    "\n",
    "# Train Word2Vec model\n",
    "model = Word2Vec(tokenized_sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Get word vector for 'cat'\n",
    "vector_cat = model.wv['cat']\n",
    "vector_cat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10.How can you use Doc2Vec to embed documents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.2322699e-03, -5.9790984e-03, -9.8876301e-03,  8.5572470e-03,\n",
       "        3.5604439e-03,  2.6277432e-04, -9.8853465e-03, -5.1619993e-03,\n",
       "       -9.7168991e-03,  2.0116097e-03,  2.8330807e-03,  4.6403855e-03,\n",
       "       -4.2971005e-03, -3.1479211e-03, -3.0759308e-03, -8.7302690e-03,\n",
       "        2.1684545e-03,  9.2274500e-03, -9.5014656e-03, -3.4542733e-03,\n",
       "       -3.7631877e-03,  2.6131766e-03, -5.6972150e-03,  2.6235376e-03,\n",
       "        5.7998220e-03, -8.1086131e-03, -8.3340909e-03, -9.9575315e-03,\n",
       "        4.9368604e-03, -9.1284197e-03,  5.8462350e-03,  6.8038353e-03,\n",
       "       -6.5100077e-03, -4.5151752e-03, -1.2564737e-03,  1.6444849e-03,\n",
       "       -1.4786971e-03, -8.5409954e-03, -3.6078824e-03,  1.7308861e-03,\n",
       "       -2.0556301e-03, -7.2331424e-03,  4.1850666e-03, -8.5811997e-03,\n",
       "        2.7123191e-03, -4.6131499e-03,  6.4740243e-04, -2.0547754e-03,\n",
       "        5.4161190e-03, -8.0037722e-03, -2.1191705e-03, -8.8654844e-05,\n",
       "       -6.6341343e-03, -6.5310663e-03, -1.9344472e-03,  8.8058384e-03,\n",
       "       -1.2641530e-03,  3.5395736e-03, -5.7549155e-03,  8.8139689e-03,\n",
       "        2.9189533e-03,  9.2814369e-03,  4.3535149e-03, -4.2023845e-03,\n",
       "        2.2440027e-03, -4.4180793e-03,  5.7727364e-03,  1.8261892e-03,\n",
       "       -2.2851920e-03, -5.8844201e-03, -8.0236970e-03, -8.5499999e-04,\n",
       "       -8.9386059e-03, -9.2234602e-03, -7.9390220e-03,  2.1713381e-03,\n",
       "       -6.4954092e-03, -7.7909031e-03,  2.1304365e-03,  2.0533935e-03,\n",
       "        8.3541740e-03,  4.6696230e-03, -9.4159627e-03, -3.4039590e-04,\n",
       "        7.8523792e-03,  2.6736762e-03,  2.6795748e-03, -4.8837843e-03,\n",
       "        6.4751231e-03,  1.6492045e-03, -7.6049929e-03,  6.8697631e-03,\n",
       "       -9.7659063e-03, -8.1560807e-03, -4.8792148e-03,  9.9397898e-03,\n",
       "        3.1169320e-03, -2.0141068e-03,  8.8949092e-03,  2.3562293e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Sample documents\n",
    "documents = [\n",
    "    \"the cat sat on the mat\",\n",
    "    \"the dog sat on the log\",\n",
    "    \"the cat chased the dog\"\n",
    "]\n",
    "\n",
    "# Tag documents\n",
    "tagged_documents = [TaggedDocument(words=word_tokenize(doc), tags=[f\"Doc_{i}\"]) for i, doc in enumerate(documents)]\n",
    "\n",
    "# Train Doc2Vec model\n",
    "model = Doc2Vec(tagged_documents, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Get document vector for 'Doc_0'\n",
    "vector_doc_0 = model.dv[\"Doc_0\"]\n",
    "vector_doc_0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11.How can you perform part-of-speech tagging?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('cat', 'NN'),\n",
       " ('sat', 'VBD'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('mat', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "#nltk.download('punkt')\n",
    "\n",
    "# Sample sentence\n",
    "sentence = \"The cat sat on the mat.\"\n",
    "\n",
    "# Tokenize and perform POS tagging\n",
    "tokens = nltk.word_tokenize(sentence)\n",
    "pos_tags = nltk.pos_tag(tokens)\n",
    "pos_tags\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. How can you find the similarity between two sentences using cosine similarity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7799154245579976"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Sample sentences\n",
    "sentence1 = \"The cat sat on the mat.\"\n",
    "sentence2 = \"The dog sat on the mat.\"\n",
    "\n",
    "# Calculate TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform([sentence1, sentence2])\n",
    "\n",
    "# Compute Cosine Similarity\n",
    "similarity = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])\n",
    "similarity[0][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13. How can you extract named entities from a sentence? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Barack Obama', 'PERSON'), ('Hawaii', 'GPE'), ('1961', 'DATE')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load SpaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Sample sentence\n",
    "sentence = \"Barack Obama was born in Hawaii in 1961.\"\n",
    "\n",
    "# Extract named entities\n",
    "doc = nlp(sentence)\n",
    "entities = [(entity.text, entity.label_) for entity in doc.ents]\n",
    "entities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14. How can you split a large document into smaller chunks of text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is a very large document',\n",
       " 'It contains many sentences',\n",
       " 'Each sentence is important.']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample text\n",
    "large_text = \"This is a very large document. It contains many sentences. Each sentence is important.\"\n",
    "\n",
    "# Split into chunks by sentence\n",
    "chunks = large_text.split(\". \")\n",
    "chunks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15. How can you calculate the TF-IDF (Term Frequency - Inverse Document Frequency) for a set of documents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>chased</th>\n",
       "      <th>dog</th>\n",
       "      <th>log</th>\n",
       "      <th>mat</th>\n",
       "      <th>on</th>\n",
       "      <th>sat</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.374207</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.492038</td>\n",
       "      <td>0.374207</td>\n",
       "      <td>0.374207</td>\n",
       "      <td>0.581211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.374207</td>\n",
       "      <td>0.492038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.374207</td>\n",
       "      <td>0.374207</td>\n",
       "      <td>0.581211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.403525</td>\n",
       "      <td>0.530587</td>\n",
       "      <td>0.403525</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.626747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        cat    chased       dog       log       mat        on       sat  \\\n",
       "0  0.374207  0.000000  0.000000  0.000000  0.492038  0.374207  0.374207   \n",
       "1  0.000000  0.000000  0.374207  0.492038  0.000000  0.374207  0.374207   \n",
       "2  0.403525  0.530587  0.403525  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "        the  \n",
       "0  0.581211  \n",
       "1  0.581211  \n",
       "2  0.626747  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Sample documents\n",
    "documents = [\n",
    "    \"the cat sat on the mat\",\n",
    "    \"the dog sat on the log\",\n",
    "    \"the cat chased the dog\"\n",
    "]\n",
    "\n",
    "# Calculate TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Convert to a DataFrame\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "tfidf_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16. How can you apply tokenization, stopword removal, and stemming in one go?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['quick', 'brown', 'fox', 'jump', 'lazi', 'dog', '.']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Sample text\n",
    "text = \"The quick brown fox jumps over the lazy dog.\"\n",
    "\n",
    "# Tokenize\n",
    "tokens = nltk.word_tokenize(text)\n",
    "\n",
    "# Remove stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "\n",
    "# Perform stemming\n",
    "stemmer = PorterStemmer()\n",
    "stemmed_tokens = [stemmer.stem(word) for word in filtered_tokens]\n",
    "\n",
    "stemmed_tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 17.How can you visualize the frequency distribution of words in a sentence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample text\n",
    "text = \"The cat sat on the mat. The dog sat on the log.\"\n",
    "\n",
    "# Tokenize and calculate frequency\n",
    "tokens = nltk.word_tokenize(text)\n",
    "freq_dist = FreqDist(tokens)\n",
    "\n",
    "# Plot frequency distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "freq_dist.plot(30, cumulative=False)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
